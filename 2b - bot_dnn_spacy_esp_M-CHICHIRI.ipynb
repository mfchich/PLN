{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV8wZ0MTKjv_"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Bot basado en reglas con DNN + Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marcelo Chichiri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_9z3H-yKrcK"
   },
   "source": [
    "#### Datos\n",
    "Este ejemplo se inspiró en otro Bot en inglés creado con NLTK, lo tienen como referencia para hacer lo mismo en inglés:\\\n",
    "[LINK](https://towardsdatascience.com/a-simple-chatbot-in-python-with-deep-learning-3e8669997758)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este desafío usé un dataset para un bot de un servicio de venta y reclamos de un servicio de TV por cable (Cablin).\n",
    "\n",
    "Se definieron 11 clases ('Subscripcion', 'agradecimientos', 'baja', 'consulta_pago', 'contacto', 'despedida', 'hablar_humano', 'nombre', 'reclamos_cobro', 'reclamos_servicios', 'saludos') con un vocabulario de 93 términos.\n",
    "\n",
    "Para implementar este desafío se realizaron las siguientes taréas\n",
    "* Se eliminaron mas signos de puntuación, como \"~@#$%^&*()_+<>\"\n",
    "* Para ajustar un poco el modelo tuve que agregar algunos patterns que no había considerado inicialmente. Esto hizo que el modelo mejorase su respuesta. \n",
    "* Se probó sin stop words y con stop words. El resultado con stop words empeoró para algunos casos, ya que se eliminaban algunos terminos como 'no', 'como' y 'este' que hacían que algunos  documentos no tuviera sentido.Para evitar este problema se eliminó estos tres términos de la lista de stop words.\n",
    "\n",
    "El resultado, dentro de este modelo básico, creo que resultó muy satisfactorio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVZakCzAjGN"
   },
   "source": [
    "### 1 - Instalar dependencias\n",
    "Para poder utilizar Spacy en castellano es necesario agregar la librería \"spacy-stanza\" para lematizar palabras en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zd8NLa4gsSmT"
   },
   "outputs": [],
   "source": [
    "# La última versión de spacy-stanza (>1.0) es compatible solo con spacy >=3.0\n",
    "# Nota: spacy 3.0 incorpora al pepiline nlp transformers\n",
    "#!pip install -U spacy==3.1 --quiet\n",
    "#!pip install -U spacy-stanza==1.0.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kzao7XO9NJAq"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignora los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z_ExOb8uvjqK"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e908d615224e7c9a56e9130c9d55df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 15:07:38 INFO: Downloading default packages for language: es (Spanish)...\n",
      "2022-10-30 15:07:40 INFO: File exists: C:\\Users\\Marcelo\\stanza_resources\\es\\default.zip.\n",
      "2022-10-30 15:07:50 INFO: Finished downloading models and saved to C:\\Users\\Marcelo\\stanza_resources.\n",
      "2022-10-30 15:07:51 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-10-30 15:07:51 INFO: Use device: cpu\n",
      "2022-10-30 15:07:51 INFO: Loading: tokenize\n",
      "2022-10-30 15:07:51 INFO: Loading: mwt\n",
      "2022-10-30 15:07:51 INFO: Loading: pos\n",
      "2022-10-30 15:07:51 INFO: Loading: lemma\n",
      "2022-10-30 15:07:51 INFO: Loading: depparse\n",
      "2022-10-30 15:07:52 INFO: Loading: ner\n",
      "2022-10-30 15:07:55 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import spacy_stanza\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Vamos a usar SpaCy-Stanza. Stanza es una librería de NLP de Stanford\n",
    "# SpaCy armó un wrapper para los pipelines y modelos de Stanza\n",
    "# https://stanfordnlp.github.io/stanza/\n",
    "\n",
    "# Descargar el diccionario en español y armar el pipeline de NLP con spacy\n",
    "stanza.download(\"es\")\n",
    "nlp = spacy_stanza.load_pipeline(\"es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wF10RjVMBdV"
   },
   "source": [
    "### 2 - Herramientas de preprocesamiento de datos\n",
    "Entre las tareas de procesamiento de texto en español se implementa:\n",
    "- Quitar acentos y caracteres especiales\n",
    "- Quitar números\n",
    "- Quitar símbolos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZxoD2hEExmuX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# El preprocesamento en castellano requiere más trabajo\n",
    "\n",
    "# Referencia de regex:\n",
    "# https://docs.python.org/3/library/re.html\n",
    "\n",
    "def preprocess_clean_text(text):    \n",
    "    # sacar tildes de las palabras:\n",
    "    #print(text)\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    # quitar caracteres especiales\n",
    "    #pattern = r'[^a-zA-z0-9.,<>@#$%^&*()~=+|¡!?¿/:;\\´\\\"\\'\\s]' # [^ : ningún caracter de todos estos\n",
    "    pattern = r'[^a-zA-z0-9.~@#$%^&*()_+<>,!?/:;\\\"\\'\\s]'\n",
    "    # (termina eliminando cualquier caracter distinto de los del regex)\n",
    "    text = re.sub(pattern, '', text)\n",
    "    #pattern = r'[^a-zA-z.,<>@#$%^&*()~=+|¡!?¿/:;\\´\\\"\\'\\s]' # igual al anterior pero sin cifras numéricas\n",
    "    pattern = r'[^a-zA-z.~@#$%^&*()_+<>,!?/:;\\\"\\'\\s]'\n",
    "    # quitar números\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # quitar caracteres de puntuación\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "       # Stop words\n",
    "    #print(text)\n",
    "    #text = [w for w in text if w not in nltk_stop_words]\n",
    "    #print(text)\n",
    "    ###### \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I9V-S8JbrtNn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: hola personas ideas estas cosas y los peces y los murcielagos  \n",
      "Lematización de cada token:\n",
      "[hola, 'holar']\n",
      "[personas, 'persona']\n",
      "[ideas, 'idea']\n",
      "[estas, 'este']\n",
      "[cosas, 'cosa']\n",
      "[y, 'y']\n",
      "[los, 'el']\n",
      "[peces, 'pez']\n",
      "[y, 'y']\n",
      "[los, 'el']\n",
      "[murcielagos, 'murcielago']\n",
      "[ , ' ']\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de como fuciona\n",
    "text = \"hola personas Ideas! estás cosas y los peces y los murciélagos # <.\"\n",
    "\n",
    "# Antes de preprocesar los datos se pasa a minúsculas todo el texto\n",
    "tokes = nlp(preprocess_clean_text(text.lower()))\n",
    "print(\"tokens:\", tokes)\n",
    "print(\"Lematización de cada token:\")\n",
    "for token in tokes:\n",
    "    print([token, token.lemma_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilRbn0KfMm2r"
   },
   "source": [
    "### 3 - Diccionario de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NgIGpjymNEH7"
   },
   "outputs": [],
   "source": [
    "# Dataset en formato JSON que representa las posibles preguntas (patterns)\n",
    "# y las posibles respuestas por categoría (tag)\n",
    "# Los \"patterns\" van a formar el corpus para entrenar el clasificador que clasifica en tags\n",
    "# \"respones\" son las respuestas predeterminadas posibles para cada tag\n",
    "\n",
    "#Servicio de venta y reclamo de TV por cable\n",
    "\n",
    "dataset = {\"intents\": [\n",
    "             {\"tag\": \"saludos\",\n",
    "              \"patterns\": [\"Hola\", \"¿Cómo estás?\", \"¿Qué tal?\", \"Buen día\",  \"Buenas tardes\",  \"Buenas noches\" ],\n",
    "              \"responses\": [\"Hola!, Soy Cablin ¿En te puedo ayudar?\", \"Hola, Soy Cablin ¿En te puedo ayudar?\"],\n",
    "             },\n",
    "             {\"tag\": \"nombre\",\n",
    "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién sos?\", \"¿Como te llamas?\", \"¿Con quien estoy hablando?\"\n",
    "                          \"¿Con quien hablo?\"],\n",
    "              \"responses\": [\"Mi nombre es Cablin\", \"Yo soy Cablin\", \"Estas hablando con Cablin\"]\n",
    "             },\n",
    "             {\"tag\": \"contacto\",\n",
    "              \"patterns\": [\"contacto\", \"número de contacto\", \"número de teléfono\", \"número de whatsapp\", \"whatsapp\"],\n",
    "              \"responses\": [\"Podes contactarnos al 011-000-1111\", \"Podés contactarnos por whatsapp al 011-000-2222\"]\n",
    "             },\n",
    "             {\"tag\": \"reclamos_servicios\",\n",
    "              \"patterns\": [\"no funciona\", \"no enciende\", \"no se ve\", \"se apaga\", \n",
    "                           \"se ve con lluvia\", \"Se desconecta\", \"tengo problemas\", \"Tengo problemas con el cable\",\n",
    "                          \"El sistema es malo\", \"El sistema es una porquería\", \"El servicio es deficiente\", \n",
    "                           \"El cable se corta\", \"se ve mal\", \"No se ven algunos canales\", \"Necesito un técnico\",\n",
    "                          \"quiero soporte de un tecnico\", \"quiero hablar con un tecnico\"],\n",
    "              \"responses\": [\"Por problemas técnicos comunicarte al 011-000-1111 (opcion 1) para programar una vista del técnico\",\n",
    "                            \"Por problemas técnicos comunicate al 011-000-1111 (opcion 1) para solicitar la visita del técnico\",\n",
    "                           \"Por problemas técnicos llama al 011-000-1111 (opcion 1) para agendar una visita del técnico\"],\n",
    "             },\n",
    "             {\"tag\": \"Subscripcion\",\n",
    "              \"patterns\": [\"¿Cuanto cuesta?\", \"¿Que planes hay?\", \"¿Como me subscribo?\", \n",
    "                           \"¿Hay descuento?\", \"¿Hay promociones?\", \"Quiero subscribirme\", \"deseo subscribirme\"],\n",
    "              \"responses\": [\"En www.cablin.com.ar podes encontar todos los planes y promociones. Para subscribirte podes enviar un mail con tus datos a <mail@subscripcion> o llamar al 011-000-1111 (opción 3)\", \n",
    "                            \"En nuestra web www.cablin.com.ar se detallan todos los planes y promociones. Para subscribirte envia un mail a <mail@subscripcion> o llamar al 011-000-1111 (opción 3)\"],\n",
    "             },\n",
    "             {\"tag\": \"baja\",\n",
    "              \"patterns\": [\"Me quiero dar de baja\", \"Quiero darme de baja\", \"¿Como me borro?\", \n",
    "                           \"¿como me doy de baja?\", \"Quiero anular subscripción\", \n",
    "                           \"Quiero terminar subscripción\"],\n",
    "              \"responses\": [\"Para darte de baja o cambiar tu subscripción podés llamar al 011-000-1111 (opción 2) para hablar con un representante\", \n",
    "                            \"Para darte de baja o cambiar tu subscripción podés comunicate al 011-000-1111 (opción 2) para hablar con un representante\",\n",
    "                           \"Para darte de baja o cambiar tu subscripción llamá al 011-000-1111 (opción 2) y te atenderá un representante\"],\n",
    "             },\n",
    "             {\"tag\": \"consulta_pago\",\n",
    "              \"patterns\": [\"¿cuales son los metodos de pagos?\", \"¿cuales son las formas de pago?\", \n",
    "                           \"¿Como pago la factura?\", \"¿puedo pagar con tarjeta?\", \"¿tienen debito automatico?\", \n",
    "                           \"¿tienen mercado de pago?\"],\n",
    "              \"responses\": [\"En la pagina www.cablin.com.ar podrás encontrar el detalle de todas las formas de pago\", \n",
    "                            \"Visita nuestra web www.cablin.com.ar para ver todas las formas de pago\"],\n",
    "            },\n",
    "             {\"tag\": \"reclamos_cobro\",\n",
    "              \"patterns\": [\"No me llegó la factura\", \"La factura está mal\", \"Me cobraron de mas\",\n",
    "                           \"Me esta cobrando de mas\", \"No me hacen el descuento\", \"es muy caro\"],\n",
    "              \"responses\": [\"Para consultar por facturación podés llamar al 011-000-1111 (opción 4) para hablar con un representante\", \n",
    "                            \"Para consultar por facturación podés podés comunicate al 011-000-1111 (opción 4) para hablar con un representante\",\n",
    "                           \"Para consultar por facturación llamá al 011-000-1111 (opción 4) y te atenderá un representante\"],\n",
    "            },\n",
    "             {\"tag\": \"hablar_humano\",\n",
    "              \"patterns\": [\"Quiero hablar con un humano\", \"humano\", \n",
    "                           \"pasame con un humano\", \"quiero hablar con una persona\", \"persona\",\n",
    "                          \"quiero hablar con alguien humano\"],\n",
    "              \"responses\": [\"Para hablar con un representante podés llamar al 011-000-1111\", \n",
    "                            \"Comunicate al 011-000-1111 para hablar con un representante\"],\n",
    "            },    \n",
    "            {\"tag\": \"agradecimientos\",\n",
    "              \"patterns\": [ \"Muchas gracias\", \"Gracias\", \"Agradecido\"],\n",
    "              \"responses\": [\"Por nada!, cualquier otra consulta podes escribirme\", \n",
    "                            \"Gracias a vos por comunicarte con Cablin\",\n",
    "                            \"A tu disposición para cualquier cosulta\"],\n",
    "             },\n",
    "             {\"tag\": \"despedida\",\n",
    "              \"patterns\": [ \"Chau\", \"Hasta luego!\", \"adios\", \"hasta luego\", ],\n",
    "              \"responses\": [\"Hasta luego!, gracias por tu visita\", \"Hablamos luego!, gracias por tu visita\"]\n",
    "             }\n",
    "]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19PEDmIDfLRu"
   },
   "source": [
    "### 4 - Preprocesamiento y armado del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abre el diccionario de stop words y elimina algunas palabras que pueden ser útiles\n",
    "\n",
    "nltk_stop_words = set(stopwords.words(\"spanish\"))\n",
    "for palabra in (['no', 'como', 'este']):\n",
    "    nltk_stop_words.remove(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b3HP8abHNRk3"
   },
   "outputs": [],
   "source": [
    "# Datos que necesitaremos, las palabras o vocabulario\n",
    "words = []\n",
    "classes = []\n",
    "doc_X = []\n",
    "doc_y = []\n",
    "\n",
    "# Por cada intención (intents) debemos tomar los patrones que la caracterízan\n",
    "# a esa intención y transformarla a tokens para almacenar en doc_X\n",
    "\n",
    "# El tag de cada intención se almacena como doc_Y (la clase a predecir)\n",
    "# En `words` vamos a guardar el vocabulario\n",
    "# En `class` las posibles clases o tags\n",
    "\n",
    "for intent in dataset[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        # trasformar el patron a tokens\n",
    "        tokens = nlp(preprocess_clean_text(pattern.lower()))\n",
    "        # lematizar los tokens\n",
    "        for token in tokens:            \n",
    "            words.append(token.lemma_)\n",
    "        \n",
    "        doc_X.append(pattern)\n",
    "        doc_y.append(intent[\"tag\"])\n",
    "    \n",
    "    # Agregar el tag a las clases\n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "\n",
    "# Eliminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Acy-gcugNbMH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['adios', 'agradecido', 'alguien', 'alguno', 'anular', 'apagar', 'automatico', 'baja', 'borrar', 'buen', 'cable', 'canal', 'caro', 'chau', 'cobrar', 'como', 'con', 'contacto', 'cortar', 'costar', 'cual', 'cuanto', 'dar', 'de', 'debito', 'deficiente', 'desconectar', 'descuento', 'desear', 'dia', 'e', 'el', 'encender', 'estar', 'este', 'factura', 'forma', 'funcionar', 'gracias', 'haber', 'hablar', 'hacer', 'hasta', 'holar', 'humano', 'llama', 'llegar', 'lluvia', 'luego', 'mal', 'malo', 'mas', 'mercado', 'metodo', 'mucho', 'necesitar', 'no', 'noche', 'nombre', 'numero', 'pagar', 'pago', 'pasamar', 'persona', 'plan', 'poder', 'porqueria', 'problema', 'promoción', 'que', 'querer', 'quien', 'ser', 'servicio', 'sistema', 'soporte', 'subscribir', 'subscribirme', 'subscripcion', 'tal', 'tarde', 'tarjeta', 'tecnico', 'telefono', 'tener', 'terminar', 'tu', 'tú', 'uno', 'ver', 'whatsapp', 'yo', 'él']\n",
      "classes: ['Subscripcion', 'agradecimientos', 'baja', 'consulta_pago', 'contacto', 'despedida', 'hablar_humano', 'nombre', 'reclamos_cobro', 'reclamos_servicios', 'saludos']\n",
      "doc_X: ['Hola', '¿Cómo estás?', '¿Qué tal?', 'Buen día', 'Buenas tardes', 'Buenas noches', '¿Cúal es tu nombre?', '¿Quién sos?', '¿Como te llamas?', '¿Con quien estoy hablando?¿Con quien hablo?', 'contacto', 'número de contacto', 'número de teléfono', 'número de whatsapp', 'whatsapp', 'no funciona', 'no enciende', 'no se ve', 'se apaga', 'se ve con lluvia', 'Se desconecta', 'tengo problemas', 'Tengo problemas con el cable', 'El sistema es malo', 'El sistema es una porquería', 'El servicio es deficiente', 'El cable se corta', 'se ve mal', 'No se ven algunos canales', 'Necesito un técnico', 'quiero soporte de un tecnico', 'quiero hablar con un tecnico', '¿Cuanto cuesta?', '¿Que planes hay?', '¿Como me subscribo?', '¿Hay descuento?', '¿Hay promociones?', 'Quiero subscribirme', 'deseo subscribirme', 'Me quiero dar de baja', 'Quiero darme de baja', '¿Como me borro?', '¿como me doy de baja?', 'Quiero anular subscripción', 'Quiero terminar subscripción', '¿cuales son los metodos de pagos?', '¿cuales son las formas de pago?', '¿Como pago la factura?', '¿puedo pagar con tarjeta?', '¿tienen debito automatico?', '¿tienen mercado de pago?', 'No me llegó la factura', 'La factura está mal', 'Me cobraron de mas', 'Me esta cobrando de mas', 'No me hacen el descuento', 'es muy caro', 'Quiero hablar con un humano', 'humano', 'pasame con un humano', 'quiero hablar con una persona', 'persona', 'quiero hablar con alguien humano', 'Muchas gracias', 'Gracias', 'Agradecido', 'Chau', 'Hasta luego!', 'adios', 'hasta luego']\n",
      "doc_y: ['saludos', 'saludos', 'saludos', 'saludos', 'saludos', 'saludos', 'nombre', 'nombre', 'nombre', 'nombre', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'reclamos_servicios', 'Subscripcion', 'Subscripcion', 'Subscripcion', 'Subscripcion', 'Subscripcion', 'Subscripcion', 'Subscripcion', 'baja', 'baja', 'baja', 'baja', 'baja', 'baja', 'consulta_pago', 'consulta_pago', 'consulta_pago', 'consulta_pago', 'consulta_pago', 'consulta_pago', 'reclamos_cobro', 'reclamos_cobro', 'reclamos_cobro', 'reclamos_cobro', 'reclamos_cobro', 'reclamos_cobro', 'hablar_humano', 'hablar_humano', 'hablar_humano', 'hablar_humano', 'hablar_humano', 'hablar_humano', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'despedida', 'despedida', 'despedida', 'despedida']\n"
     ]
    }
   ],
   "source": [
    "print(\"words:\", words)\n",
    "print(\"classes:\", classes)\n",
    "print(\"doc_X:\", doc_X)\n",
    "print(\"doc_y:\", doc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YI0L2U7IQcvy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 93\n"
     ]
    }
   ],
   "source": [
    "# Tamaño del vocabulario\n",
    "print(\"Vocabulario:\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hqBeGKRk_q4r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: 11\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de tags\n",
    "print(\"Tags:\", len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vpbJ0guPN2Uq"
   },
   "outputs": [],
   "source": [
    "# Transformar doc_X en bag of words por oneHotEncoding\n",
    "# Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
    "\n",
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "\n",
    "for idx, doc in enumerate(doc_X):\n",
    "    # Transformar la pregunta (input) en tokens y lematizar\n",
    "    text = []\n",
    "    tokens = nlp(preprocess_clean_text(doc.lower()))\n",
    "    for token in tokens:\n",
    "        text.append(token.lemma_)\n",
    "    #print(\"text antes text_sin_stop_words\", text)\n",
    "    \n",
    "    # Elimina las stop words del texto lematizado    \n",
    "    #print(\"text antes de text_sin_stop_words\", text)\n",
    "    text = [w for w in text if w not in nltk_stop_words]\n",
    "    #print(\"text despues de text_sin_stop_words\", text)\n",
    "    \n",
    "    # Transformar los tokens en \"Bag of words\" (arrays de 1 y 0)\n",
    "    bow = []\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    \n",
    "    # Crear el array de salida (class output) correspondiente\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(doc_y[idx])] = 1\n",
    "\n",
    "    # print(\"X:\", bow, \"y:\", output_row)\n",
    "    training.append([bow, output_row])\n",
    "\n",
    "# Mezclar los datos\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "# Dividir en datos de entrada y salida\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_y = np.array(list(training[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_Hr8QaDfRf3"
   },
   "source": [
    "### 5 - Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fopb3NqcAGTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (93,) output: 11\n"
     ]
    }
   ],
   "source": [
    "# Shape de entrada y salida\n",
    "input_shape = (train_X.shape[1],)\n",
    "output_shape = train_y.shape[1]\n",
    "print(\"input:\", input_shape, \"output:\", output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xy7tzkwdOZx9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               12032     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,003\n",
      "Trainable params: 21,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo DNN\n",
    "# - Modelo secuencial\n",
    "# - Con regularización\n",
    "# - softmax y optimizador Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_shape, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r6hi4EcdOghm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 2.4083 - accuracy: 0.0714\n",
      "Epoch 2/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3700 - accuracy: 0.0857\n",
      "Epoch 3/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3715 - accuracy: 0.1143\n",
      "Epoch 4/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3646 - accuracy: 0.1143\n",
      "Epoch 5/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3212 - accuracy: 0.2143\n",
      "Epoch 6/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3308 - accuracy: 0.1571\n",
      "Epoch 7/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2633 - accuracy: 0.2571\n",
      "Epoch 8/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2837 - accuracy: 0.2143\n",
      "Epoch 9/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2420 - accuracy: 0.2286\n",
      "Epoch 10/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2045 - accuracy: 0.3857\n",
      "Epoch 11/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2399 - accuracy: 0.2143\n",
      "Epoch 12/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2465 - accuracy: 0.2714\n",
      "Epoch 13/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1978 - accuracy: 0.3286\n",
      "Epoch 14/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1703 - accuracy: 0.3571\n",
      "Epoch 15/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1441 - accuracy: 0.4000\n",
      "Epoch 16/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1758 - accuracy: 0.3571\n",
      "Epoch 17/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1262 - accuracy: 0.4000\n",
      "Epoch 18/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1218 - accuracy: 0.3286\n",
      "Epoch 19/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.1328 - accuracy: 0.3000\n",
      "Epoch 20/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0677 - accuracy: 0.3429\n",
      "Epoch 21/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0398 - accuracy: 0.3571\n",
      "Epoch 22/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9903 - accuracy: 0.5000\n",
      "Epoch 23/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9959 - accuracy: 0.4143\n",
      "Epoch 24/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0479 - accuracy: 0.3571\n",
      "Epoch 25/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9986 - accuracy: 0.4143\n",
      "Epoch 26/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8624 - accuracy: 0.4000\n",
      "Epoch 27/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9662 - accuracy: 0.3857\n",
      "Epoch 28/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9102 - accuracy: 0.4143\n",
      "Epoch 29/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8823 - accuracy: 0.4143\n",
      "Epoch 30/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8931 - accuracy: 0.3714\n",
      "Epoch 31/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8130 - accuracy: 0.4714\n",
      "Epoch 32/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7765 - accuracy: 0.4429\n",
      "Epoch 33/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7749 - accuracy: 0.4143\n",
      "Epoch 34/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8140 - accuracy: 0.3857\n",
      "Epoch 35/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6929 - accuracy: 0.4857\n",
      "Epoch 36/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6612 - accuracy: 0.4857\n",
      "Epoch 37/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6539 - accuracy: 0.5000\n",
      "Epoch 38/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6438 - accuracy: 0.5571\n",
      "Epoch 39/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5974 - accuracy: 0.4714\n",
      "Epoch 40/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5045 - accuracy: 0.5714\n",
      "Epoch 41/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.5489 - accuracy: 0.5857\n",
      "Epoch 42/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6137 - accuracy: 0.5571\n",
      "Epoch 43/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4959 - accuracy: 0.5571\n",
      "Epoch 44/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4415 - accuracy: 0.6143\n",
      "Epoch 45/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5029 - accuracy: 0.5857\n",
      "Epoch 46/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3965 - accuracy: 0.6571\n",
      "Epoch 47/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4483 - accuracy: 0.5857\n",
      "Epoch 48/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3332 - accuracy: 0.6286\n",
      "Epoch 49/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3588 - accuracy: 0.6143\n",
      "Epoch 50/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4772 - accuracy: 0.5286\n",
      "Epoch 51/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3704 - accuracy: 0.6857\n",
      "Epoch 52/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.2225 - accuracy: 0.6714\n",
      "Epoch 53/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2826 - accuracy: 0.6571\n",
      "Epoch 54/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2712 - accuracy: 0.6143\n",
      "Epoch 55/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1852 - accuracy: 0.6714\n",
      "Epoch 56/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0874 - accuracy: 0.7714\n",
      "Epoch 57/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1873 - accuracy: 0.7143\n",
      "Epoch 58/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1953 - accuracy: 0.6714\n",
      "Epoch 59/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0892 - accuracy: 0.7714\n",
      "Epoch 60/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0429 - accuracy: 0.8143\n",
      "Epoch 61/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1055 - accuracy: 0.7000\n",
      "Epoch 62/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0286 - accuracy: 0.7714\n",
      "Epoch 63/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0738 - accuracy: 0.7143\n",
      "Epoch 64/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9799 - accuracy: 0.7286\n",
      "Epoch 65/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9653 - accuracy: 0.7571\n",
      "Epoch 66/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9328 - accuracy: 0.8286\n",
      "Epoch 67/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0103 - accuracy: 0.7571\n",
      "Epoch 68/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8758 - accuracy: 0.8143\n",
      "Epoch 69/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8624 - accuracy: 0.8286\n",
      "Epoch 70/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9464 - accuracy: 0.8000\n",
      "Epoch 71/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8453 - accuracy: 0.8143\n",
      "Epoch 72/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7760 - accuracy: 0.8714\n",
      "Epoch 73/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8541 - accuracy: 0.7714\n",
      "Epoch 74/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8742 - accuracy: 0.8143\n",
      "Epoch 75/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7539 - accuracy: 0.8429\n",
      "Epoch 76/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8146 - accuracy: 0.7857\n",
      "Epoch 77/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7586 - accuracy: 0.8000\n",
      "Epoch 78/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6704 - accuracy: 0.9000\n",
      "Epoch 79/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.9000\n",
      "Epoch 80/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6598 - accuracy: 0.9143\n",
      "Epoch 81/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.8857\n",
      "Epoch 82/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.8857\n",
      "Epoch 83/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.9000\n",
      "Epoch 84/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.8571\n",
      "Epoch 85/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.8571\n",
      "Epoch 86/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.9000\n",
      "Epoch 87/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.8857\n",
      "Epoch 88/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.8143\n",
      "Epoch 89/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.9000\n",
      "Epoch 90/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.8857\n",
      "Epoch 91/250\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.8429\n",
      "Epoch 92/250\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8429\n",
      "Epoch 93/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.8857\n",
      "Epoch 94/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.8571\n",
      "Epoch 95/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.8143\n",
      "Epoch 96/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.8857\n",
      "Epoch 97/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.9000\n",
      "Epoch 98/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.9000\n",
      "Epoch 99/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.9429\n",
      "Epoch 100/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.9143\n",
      "Epoch 101/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.9429\n",
      "Epoch 102/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.9143\n",
      "Epoch 103/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.9571\n",
      "Epoch 104/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.8857\n",
      "Epoch 105/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.9143\n",
      "Epoch 106/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.9143\n",
      "Epoch 107/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.9429\n",
      "Epoch 108/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.9143\n",
      "Epoch 109/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.9429\n",
      "Epoch 110/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.9571\n",
      "Epoch 111/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.9286\n",
      "Epoch 112/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.9714\n",
      "Epoch 113/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.9143\n",
      "Epoch 114/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.9714\n",
      "Epoch 115/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.9143\n",
      "Epoch 116/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2866 - accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.9429\n",
      "Epoch 118/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3211 - accuracy: 0.9571\n",
      "Epoch 119/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3075 - accuracy: 0.9143\n",
      "Epoch 120/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.9143\n",
      "Epoch 121/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3653 - accuracy: 0.9571\n",
      "Epoch 122/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.9143\n",
      "Epoch 123/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2607 - accuracy: 0.9714\n",
      "Epoch 124/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2663 - accuracy: 0.9857\n",
      "Epoch 125/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2643 - accuracy: 0.9714\n",
      "Epoch 126/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.9429\n",
      "Epoch 127/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.9571\n",
      "Epoch 128/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.9429\n",
      "Epoch 129/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3392 - accuracy: 0.9143\n",
      "Epoch 130/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2476 - accuracy: 0.9429\n",
      "Epoch 131/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3229 - accuracy: 0.9429\n",
      "Epoch 132/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.9429\n",
      "Epoch 133/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2098 - accuracy: 0.9857\n",
      "Epoch 134/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2070 - accuracy: 0.9857\n",
      "Epoch 135/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 0.9857\n",
      "Epoch 136/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.9714\n",
      "Epoch 137/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2865 - accuracy: 0.9714\n",
      "Epoch 138/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2538 - accuracy: 0.9429\n",
      "Epoch 139/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2123 - accuracy: 0.9857\n",
      "Epoch 140/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9714\n",
      "Epoch 141/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.9000\n",
      "Epoch 142/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1957 - accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2308 - accuracy: 0.9857\n",
      "Epoch 144/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9714\n",
      "Epoch 145/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2617 - accuracy: 0.9143\n",
      "Epoch 146/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2062 - accuracy: 0.9571\n",
      "Epoch 147/250\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2512 - accuracy: 0.9429\n",
      "Epoch 148/250\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2519 - accuracy: 0.9286\n",
      "Epoch 149/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2023 - accuracy: 0.9714\n",
      "Epoch 151/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1923 - accuracy: 0.9714\n",
      "Epoch 152/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.9429\n",
      "Epoch 153/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1783 - accuracy: 0.9857\n",
      "Epoch 154/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1672 - accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2249 - accuracy: 0.9429\n",
      "Epoch 156/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2128 - accuracy: 0.9429\n",
      "Epoch 157/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1772 - accuracy: 0.9857\n",
      "Epoch 158/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1660 - accuracy: 0.9571\n",
      "Epoch 159/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2602 - accuracy: 0.9286\n",
      "Epoch 160/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2370 - accuracy: 0.9714\n",
      "Epoch 161/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1464 - accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1250 - accuracy: 0.9857\n",
      "Epoch 163/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1592 - accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 0.9714\n",
      "Epoch 165/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1345 - accuracy: 0.9857\n",
      "Epoch 166/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1487 - accuracy: 1.0000\n",
      "Epoch 167/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1176 - accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1325 - accuracy: 0.9857\n",
      "Epoch 169/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2345 - accuracy: 0.9286\n",
      "Epoch 170/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.9571\n",
      "Epoch 171/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1748 - accuracy: 0.9714\n",
      "Epoch 172/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1515 - accuracy: 0.9714\n",
      "Epoch 173/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2054 - accuracy: 0.9714\n",
      "Epoch 174/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9714\n",
      "Epoch 175/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1724 - accuracy: 0.9429\n",
      "Epoch 176/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.9857\n",
      "Epoch 177/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.9857\n",
      "Epoch 178/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 0.9714\n",
      "Epoch 179/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2066 - accuracy: 0.9857\n",
      "Epoch 180/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0984 - accuracy: 0.9857\n",
      "Epoch 181/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1736 - accuracy: 0.9714\n",
      "Epoch 182/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1812 - accuracy: 0.9429\n",
      "Epoch 183/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1201 - accuracy: 0.9857\n",
      "Epoch 185/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1089 - accuracy: 0.9857\n",
      "Epoch 186/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1688 - accuracy: 0.9857\n",
      "Epoch 187/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0808 - accuracy: 0.9857\n",
      "Epoch 189/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1328 - accuracy: 0.9571\n",
      "Epoch 190/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1442 - accuracy: 0.9857\n",
      "Epoch 191/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1638 - accuracy: 0.9571\n",
      "Epoch 192/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1350 - accuracy: 0.9714\n",
      "Epoch 195/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1051 - accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.9571\n",
      "Epoch 197/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9857\n",
      "Epoch 198/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1451 - accuracy: 0.9714\n",
      "Epoch 199/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.9714\n",
      "Epoch 200/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.9857\n",
      "Epoch 201/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1823 - accuracy: 0.9429\n",
      "Epoch 202/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1035 - accuracy: 0.9571\n",
      "Epoch 203/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1209 - accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 0.9857\n",
      "Epoch 205/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1176 - accuracy: 0.9571\n",
      "Epoch 206/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1437 - accuracy: 0.9857\n",
      "Epoch 207/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9857\n",
      "Epoch 208/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.9571\n",
      "Epoch 209/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1105 - accuracy: 0.9857\n",
      "Epoch 210/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1497 - accuracy: 0.9571\n",
      "Epoch 211/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1667 - accuracy: 0.9714\n",
      "Epoch 212/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0996 - accuracy: 0.9857\n",
      "Epoch 213/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0986 - accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9857\n",
      "Epoch 215/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0935 - accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1368 - accuracy: 0.9714\n",
      "Epoch 218/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1141 - accuracy: 0.9857\n",
      "Epoch 219/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9857\n",
      "Epoch 220/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0948 - accuracy: 0.9714\n",
      "Epoch 221/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1175 - accuracy: 0.9714\n",
      "Epoch 222/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 0.9857\n",
      "Epoch 223/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1061 - accuracy: 0.9714\n",
      "Epoch 224/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1167 - accuracy: 0.9857\n",
      "Epoch 225/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0924 - accuracy: 0.9857\n",
      "Epoch 226/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0875 - accuracy: 0.9857\n",
      "Epoch 227/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0919 - accuracy: 0.9714\n",
      "Epoch 228/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1021 - accuracy: 0.9857\n",
      "Epoch 229/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0951 - accuracy: 0.9714\n",
      "Epoch 233/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 0.9571\n",
      "Epoch 234/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9857\n",
      "Epoch 235/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0856 - accuracy: 0.9857\n",
      "Epoch 236/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1144 - accuracy: 0.9857\n",
      "Epoch 238/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1305 - accuracy: 0.9571\n",
      "Epoch 241/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0857 - accuracy: 0.9857\n",
      "Epoch 242/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0915 - accuracy: 0.9714\n",
      "Epoch 243/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0538 - accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0640 - accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0809 - accuracy: 0.9714\n",
      "Epoch 246/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1119 - accuracy: 0.9857\n",
      "Epoch 247/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 0.9571\n",
      "Epoch 248/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9857\n",
      "Epoch 249/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9714\n",
      "Epoch 250/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=train_X, y=train_y, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Pb1GZDjGRP6Q"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eTVDnrV0mDRf"
   },
   "outputs": [],
   "source": [
    "# Guardar lo necesario para poder re-utilizar este modelo en el futuro\n",
    "# el vocabulario utilizado (words)\n",
    "# las posibles clases\n",
    "# el modelo\n",
    "import pickle\n",
    "pickle.dump(words, open('words.pkl','wb'))\n",
    "pickle.dump(classes, open('classes.pkl','wb'))\n",
    "model.save('chatbot_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnD1WvhBfVYR"
   },
   "source": [
    "### 6 - Testing y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kqBdSGt8Orkm"
   },
   "outputs": [],
   "source": [
    "# convertir texto de entrada del usuario a tokens\n",
    "\n",
    "def text_in_stop_words(text):\n",
    "    text_sin_stop_words = [w for w in text if w not in nltk_stop_words]\n",
    "    return text_sin_stop_words\n",
    "\n",
    "def text_to_tokens(text):\n",
    "    lemma_tokens = []\n",
    "    tokens = nlp(preprocess_clean_text(text.lower()))\n",
    "    for token in tokens:\n",
    "        lemma_tokens.append(token.lemma_)\n",
    "    \n",
    "    #print(\"lemma_tokens\", lemma_tokens)\n",
    "    lemma_tokens = text_in_stop_words(lemma_tokens)\n",
    "    #print(\"lemma_tokens sin stop\", lemma_tokens)\n",
    "    return lemma_tokens\n",
    "\n",
    "# transformar el texto de entrada tokenizado a una representación OHE\n",
    "def bag_of_words(text, vocab): \n",
    "    tokens = text_to_tokens(text)\n",
    "    bow = [0] * len(vocab)\n",
    "    for w in tokens: \n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word == w: \n",
    "                bow[idx] = 1\n",
    "    #print(\"bow\", bow)\n",
    "    return np.array(bow)\n",
    "\n",
    "# usar modelo con la entrada en OHE y los labels posibles (tags)\n",
    "def pred_class(text, vocab, labels): \n",
    "    bow = bag_of_words(text, vocab)\n",
    "    #print(bow)\n",
    "    words_recognized = sum(bow)\n",
    "\n",
    "    return_list = []\n",
    "    if words_recognized > 0: # sólo si reconoció alguna palabra del vocabulario\n",
    "        result = model.predict(np.array([bow]))[0] # es un array de softmax\n",
    "        thresh = 0.2\n",
    "        # filtrar aquellas entradas menores al umbral `thresh`\n",
    "        y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
    "        # ordenar keys de acuerdo al valor softmax\n",
    "        y_pred.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "        # return_list es una lista de los labels de mayor a menor\n",
    "        for r in y_pred:\n",
    "            return_list.append(labels[r[0]])\n",
    "            #print(labels[r[0]], r[1])\n",
    "\n",
    "    # si no reconoció palabras del vocabulario se devuelve una lista vacía\n",
    "    return return_list\n",
    "\n",
    "# obtener una respuesta predeterminada \n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0] # tomar el tag con el mejor valor softmax\n",
    "    list_of_intents = intents_json[\"intents\"] # intents_json es todo el dataset\n",
    "    for i in list_of_intents: \n",
    "        if i[\"tag\"] == tag: # buscar el tag correspondiente y dar una respuesta predeterminada aleatoria \n",
    "            result = random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xp1vXQwdOvl7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n",
      "Q: Hola\n",
      "BOT: Hola!, Soy Cablin ¿En te puedo ayudar? \n",
      "\n",
      "Buen día\n",
      "Q: Buen día\n",
      "BOT: Hola!, Soy Cablin ¿En te puedo ayudar? \n",
      "\n",
      "Como estas?\n",
      "Q: Como estas?\n",
      "BOT: Hola!, Soy Cablin ¿En te puedo ayudar? \n",
      "\n",
      "tengo problema con el servicio\n",
      "Q: tengo problema con el servicio\n",
      "BOT: Por problemas técnicos llama al 011-000-1111 (opcion 1) para agendar una visita del técnico \n",
      "\n",
      "el cable se corta\n",
      "Q: el cable se corta\n",
      "BOT: Por problemas técnicos comunicarte al 011-000-1111 (opcion 1) para programar una vista del técnico \n",
      "\n",
      "y me cobraron de mas\n",
      "Q: y me cobraron de mas\n",
      "BOT: Para consultar por facturación podés llamar al 011-000-1111 (opción 4) para hablar con un representante \n",
      "\n",
      "tampoco me llegó la factura\n",
      "Q: tampoco me llegó la factura\n",
      "BOT: Para consultar por facturación podés podés comunicate al 011-000-1111 (opción 4) para hablar con un representante \n",
      "\n",
      "quiero saber cuales son los planes\n",
      "Q: quiero saber cuales son los planes\n",
      "BOT: Mi nombre es Cablin \n",
      "\n",
      "como hago si me quiero dar de baja?\n",
      "Q: como hago si me quiero dar de baja?\n",
      "BOT: Para darte de baja o cambiar tu subscripción llamá al 011-000-1111 (opción 2) y te atenderá un representante \n",
      "\n",
      "Ahora estoy pagando por debito, que otros medios de pago hay?\n",
      "Q: Ahora estoy pagando por debito, que otros medios de pago hay?\n",
      "BOT: Visita nuestra web www.cablin.com.ar para ver todas las formas de pago \n",
      "\n",
      "quien sos?\n",
      "Q: quien sos?\n",
      "BOT: Mi nombre es Cablin \n",
      "\n",
      "Puedo hablar con una persona?\n",
      "Q: Puedo hablar con una persona?\n",
      "BOT: Para hablar con un representante podés llamar al 011-000-1111 \n",
      "\n",
      "Con quien estoy hablando?\n",
      "Q: Con quien estoy hablando?\n",
      "BOT: Estas hablando con Cablin \n",
      "\n",
      "gracias!!\n",
      "Q: gracias!!\n",
      "BOT: Gracias a vos por comunicarte con Cablin \n",
      "\n",
      "adios\n",
      "Q: adios\n",
      "BOT: Hasta luego!, gracias por tu visita \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Salida = False\n",
    "while not Salida:\n",
    "    # pedir input al usuario\n",
    "    message = input(\"\")\n",
    "    print(\"Q:\", message)\n",
    "\n",
    "    intents = pred_class(message, words, classes)\n",
    "    if len(intents) > 0:\n",
    "        result = get_response(intents, dataset)\n",
    "        print(\"BOT:\", result, \"\\n\")\n",
    "        #print(message, words, classes, intents)\n",
    "        if \"despedida\" in intents:\n",
    "            Salida = True\n",
    "    else: # si no hubo ningún resultado que supere el umbral\n",
    "        print(\"BOT: Perdón, no comprendo la pregunta. Por favor podés reformularla\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayatkwp4fYQx"
   },
   "source": [
    "### 7 - Conclusiones\n",
    "El bot tal cual está definido es capaz de responder a bastantes tipos de preguntas con gran precisión. Algunas técnicas que podrían ensayarse para evaluar como impactan en el sistema son:\n",
    "- Filtrar los stop words\n",
    "- Utilizar TF-IDF en vez de bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tomar un ejemplo de los bots utilizados (uno de los dos) y construir el propio.\n",
    "- Sacar conclusiones de los resultados.\n",
    "\n",
    "__IMPORTANTE__: Recuerde para la entrega del ejercicio debe quedar registrado en el colab las preguntas y las respuestas del BOT para que podamos evaluar el desempeño final."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZeXqdm2EV/WEA+xr24OAL",
   "collapsed_sections": [],
   "name": "2b - bot_dnn_spacy_esp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
