 
<p align="center"> <h1 align="center">:boom: ** CARATULA EN DESARROLLO **:boom:</h1> </p>

<p align="center"> <h1 align="center">:book: Procesamiento de Lenguaje Natural (PLN) :book:</h1> </p>

<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="500" src="https://github.com/mfchich/PLN/blob/main/imagenes/PLN.JPG" ></a></p>

<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="400" src="https://github.com/mfchich/PLN/blob/main/imagenes/logoFIUBA.jpg" ></a></p>
 

## Marcelo chichiri

<a name="top"></a>
## Desafios 
* [:notebook: Desafio 1 : TF-IDF (Term frequency-Inverse term frequency) ](#desafio1) 
* [:space_invader: Desafio 2 : Construcci贸n de BOT basado en reglas](#desafio2)
* [:twisted_rightwards_arrows: Desafio 3 : Creaci贸n de embeddings de palabras basado en contexto](#desafio3)
* [:repeat_one: Desafio 4 : Predicci贸n de pr贸xima palabra](#desafio4)
* [:performing_arts: Desafio 5 : An谩lisis de sentimientos ](#desafio5)
* [  Desafio 6 : Creaci贸n de un bot conversacional](#desafio6)
## 

<a name="desafio1"></a>
## <p align="center"> TF-IDF (Term frequency-Inverse term frequency) </p>
<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="300" src="https://github.com/mfchich/PLN/blob/main/imagenes/TF_IDF.JPG" ></a></p>

### :anguished: Este desaf铆o consiste en calcular las m茅tricas TF (Term Frequency), IDF (Inverse Term Frequency) y similitud por coseno. Estas m茅tricas se utilizan como indicador de cu谩n importante es una palabra (o un t茅rmino) en un documento y, mediante el c谩lculo de similitud por coseno, poder calcular la similitud entre dos textos. 
### :toolbox: Para este desaf铆o se utilizaron herramientas de c谩lculo de Numpy.

### :relaxed: El indicador TF muestra la frecuencia de aparici贸n de un t茅rmino en un documento.  
### El indicador IDF muestra la proporci贸n de documentos en el corpus que poseen el t茅rmino dado.
### El indicador Conseno se utiliza para evaluar la similitud entre dos documentos representados por sus correspondientes vectore   

:bookmark_tabs: <a href="https://github.com/mfchich/PLN/blob/main/1a%20-%20word2vec_M-CHICHIRI.ipynb" target="_blank">Ir al c贸digo del desafio 1</a> 

[:arrow_heading_up: Volver](#top)

##
<a name="desafio2"></a>
## <p align="center"> Construcci贸n de BOT basado en reglas </p>
<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="200" src="https://github.com/mfchich/PLN/blob/main/imagenes/Bot_grande.JPG" ></a></p>
***
### :anguished: Este desaf铆o consiste en construir un bot basado en reglas que sea capaz de responder preguntas simples. En este caso se utiliz贸 un corpus para un bot de un servicio de venta y reclamos de un servicio de TV por cable (Cablin).
### :toolbox: Para este desafio se utilizaron las librer铆as SpaCy-Stanza de Stanford con funciones para NLP para tokenizar. Se cre贸 y entren贸 un modelo secuencial de Keras.  
###  :relaxed: Se definieron 11 clases ('Subscripcion', 'agradecimientos', 'baja', 'consulta_pago', 'contacto', 'despedida', 'hablar_humano', 'nombre', 'reclamos_cobro', 'reclamos_servicios', 'saludos') con un vocabulario de 93 t茅rminos.
### Considerando la reducida cantidad de clases y de t茅rminos los resultados obtenidos fueron muy buenos. 
***

:bookmark_tabs: <a href="https://github.com/mfchich/PLN/blob/main/2b%20-%20bot_dnn_spacy_esp_M-CHICHIRI.ipynb" target="_blank">Ir al c贸digo del desafio 2</a>

[:arrow_heading_up: Volver ](#top)

##
<a name="desafio3"></a>
## <p align="center"> Creaci贸n de embeddings de palabras basado en contexto </p>
<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="200" src="https://github.com/mfchich/PLN/blob/main/imagenes/Relacion_palabras.JPG" ></a></p>

###  :anguished: Este desaf铆o consiste en utilizar documentos/corpus para crear embeddings de palabras basado en ese contexto. Se utilizar谩 canciones de bandas para generar los embeddings, es decir, que los vectores tendr谩n la forma en funci贸n de como esa banda haya utilizado las palabras en sus canciones.

### :toolbox: Para este desafio se utilizaron las librer铆as Word2Vec de Gensim Doc2Vec, un modelo que representa cada Documento como un Vector.
###  :relaxed: Se us贸 un corpus de aproximadamente 40 canciones de Joan Manuel Serrat. El dataset fue creado a mano. Las letras fueron obtenidas de https://www.musica.com/letras.asp?letras=7599
### Se estableci贸 en 2 la cantidad de repeticiones m铆nimas del t茅rmino para ser tomada en cuenta. Esto es principalmente porque hay t茅rminos que se repiten poco, pero dan significado a otras que se repiten m谩s.
### La tem谩tica de los temas de cantautor es muy variada por lo cual los t茅rminos aparecen en contextos variados. Se comprueba que los t茅rminos se pueden relacionar con distintos p谩rrafos de canciones de cantautor.

:bookmark_tabs: <a href="https://github.com/mfchich/PLN/blob/main/3b-Custom_embedding_con_Gensim-M-CHICHIRI.ipynb" target="_blank">Ir al c贸digo del desafio 3</a>

[:arrow_heading_up: Volver](#top)

##
<a name="desafio4"></a>
## <p align="center"> Predicci贸n de pr贸xima palabra </p>
<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="200" src="https://github.com/mfchich/PLN/blob/main/imagenes/Proxima_palabra.JPG" ></a></p>

###  :anguished: Este desaf铆o consiste en utilizar un dataset y poner en pr谩ctica la predicci贸n de pr贸xima palabra.

### :toolbox:

###  :relaxed: Se us贸 un corpus de aproximadamente 4566 documentos (con 141318 tokens), formados por el texto del libro "La Vuelta al Mundo en 80 d铆as" y de "Viaje al Centro de la Tierra", ambos de Julio Verne, concatenados y convertidos en un archivo csv. Ambos textos fueron obtenidos de https://www.textos.info/

### Los resultados no fueron muy buenos. Se ve que la palabra predicha no se ajusta a lo que se espera de sugerencia como palabra siguiente. Esto se explica por la reducida cantidad de documentos en el corpus.

:bookmark_tabs: <a href="https://github.com/mfchich/PLN/blob/main/4d%20-%20predicci%C3%B3n_palabra_M-CHICHIRI.ipynb" target="_blank">Ir al c贸digo del desafio 4</a>

[:arrow_heading_up: Volver](#top)

##
<a name="desafio5"></a>
## <p align="center"> An谩lisis de sentimientos </p>
<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="200" src="https://github.com/mfchich/PLN/blob/main/imagenes/Analisis_sentimientos2.JPG" ></a></p>

###  :anguished: Este desaf铆o consiste en utilizar las cr铆ticas de compradores de ropa para que el sistema determine la evaluaci贸n del comprador y su cr铆tica (cuantas estrellas le asigna al producto).

### :toolbox:
### :relaxed: Se utiliz贸 como dataset cr铆ticas de compradores de ropa por eCommerce , los cuales puntuaron a cada prenda con un puntaje de 1 a 5 estrellas.

<a href="https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews" target="_blank">Referencia del dataset</a>

### El datset original tiene 5 clases, pero como est谩n muy desbalanceados se juntaron clases para concluir solo en tres clases mas balanceadas. Entonces la clase 0 ser铆a malo y regular, la clase 1 bueno y muy bueno y la clase 3 excelente/perfecto. Este cambio no balance贸 por completo el dataset pero lo mejor贸 significativamente, lo cual mejor贸 el entrenamiento del modelo.

### Se utilizaron distintas configuraciones de redes, tanto con capas lstm con conexiones bidireccionales como sin conexiones bidireccionales, adaptando las redes para cada caso, buscando el mejor resultado.

:bookmark_tabs: <a href="https://github.com/mfchich/PLN/blob/main/5%20-%20clothing_ecommerce_reviews-M-CHICHIRI.ipynb" target="_blank">Ir al c贸digo del desafio 5</a>

[:arrow_heading_up: Volver](#top)

##
<a name="desafio6"></a>
## <p align="center"> Creaci贸n de un bot conversacional </p>
<p align="center"><a target="_blank" rel="noopener noreferrer"><img width="200" src="https://github.com/mfchich/PLN/blob/main/imagenes/Bot_conversacion.JPG" ></a></p>

### :anguished: Este desaf铆o consiste en construir un BOT para responder a preguntas del usuario (QA). El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en ingl茅s, utilizado la t茅cnica seq2seq.

### :toolbox:

###  :relaxed: Se utiliz贸 una red neuronal con embeddings de Glove de dimensi贸n 50 y una capa de entrada de 128 unidades. El dataset de entrenamiento tiene aproximadamente 1980 palabras. Los resultados fueron bastante variados, en algunos casos la respuesta del bot fue buena y en otros bastante deficiente, pero considerando la reducida dimensi贸n del corpus de entrenamiento, los resultados generales fueron aceptables.

:bookmark_tabs: <a href="https://github.com/mfchich/PLN/blob/main/6-%20bot_qa_M-CHICHIRI.ipynb" target="_blank">Ir al c贸digo del desafio 6</a>

[:arrow_heading_up: Volver](#top)
